{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-05T08:17:42.719285Z",
     "start_time": "2024-03-05T08:17:42.713508Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2, 3])"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst = [[1, 2, 3], [3, 4, 6]]\n",
    "np_array = np.array(lst)\n",
    "tensor = torch.tensor(np_array)\n",
    "tensor.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T08:17:42.995630Z",
     "start_time": "2024-03-05T08:17:42.961756Z"
    }
   },
   "id": "86aa97d1d120d605",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "torch.int64"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.dtype"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T08:17:52.161296Z",
     "start_time": "2024-03-05T08:17:52.138203Z"
    }
   },
   "id": "c1f5146600e1c0e6",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cpu')"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.device"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T08:17:57.867356Z",
     "start_time": "2024-03-05T08:17:57.841381Z"
    }
   },
   "id": "854f4b80777ed5f",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T08:22:34.720742Z",
     "start_time": "2024-03-05T08:22:34.709415Z"
    }
   },
   "id": "dd30431eace0812d",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1609]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input_tensor = torch.Tensor([[2, 3, 6, 7, 9, 3, 2, 1]])\n",
    "\n",
    "# Implement a small neural network with exactly two linear layers\n",
    "model = nn.Sequential(nn.Linear(8, 1),\n",
    "                      nn.Linear(1, 1)\n",
    "                      )\n",
    "\n",
    "output = model(input_tensor)\n",
    "print(output)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T08:27:26.388190Z",
     "start_time": "2024-03-05T08:27:26.354155Z"
    }
   },
   "id": "24f133766c24b72c",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6900]])\n"
     ]
    }
   ],
   "source": [
    "input_tensor = torch.tensor([[0.8]])\n",
    "\n",
    "# Create a sigmoid function and apply it on input_tensor\n",
    "sigmoid = nn.Sigmoid()\n",
    "probability = sigmoid(input_tensor)\n",
    "print(probability)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T08:34:35.891824Z",
     "start_time": "2024-03-05T08:34:35.881397Z"
    }
   },
   "id": "76d4c2f146c0c8f6",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.2828e-01, 1.1698e-04, 5.7492e-01, 3.4961e-02, 1.5669e-01, 1.0503e-01]])\n"
     ]
    }
   ],
   "source": [
    "input_tensor = torch.tensor([[1.0, -6.0, 2.5, -0.3, 1.2, 0.8]])\n",
    "\n",
    "# Create a softmax function and apply it on input_tensor\n",
    "softmax = nn.Softmax(dim=-1)\n",
    "probabilities = softmax(input_tensor)\n",
    "print(probabilities)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T08:35:35.201641Z",
     "start_time": "2024-03-05T08:35:35.191924Z"
    }
   },
   "id": "7131520ca77e1834",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9898]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input_tensor = torch.Tensor([[3, 4, 6, 2, 3, 6, 8, 9]])\n",
    "\n",
    "# Implement a small neural network for binary classification\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(8, 1),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "output = model(input_tensor)\n",
    "print(output)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T08:47:50.202594Z",
     "start_time": "2024-03-05T08:47:50.182674Z"
    }
   },
   "id": "db5272f76bb1761d",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.1091]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input_tensor = torch.Tensor([[3, 4, 6, 7, 10, 12, 2, 3, 6, 8, 9]])\n",
    "\n",
    "# Implement a neural network with exactly four linear layers\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(11, 3),\n",
    "    nn.Linear(3, 12),\n",
    "    nn.Linear(12, 8),\n",
    "    nn.Linear(8, 1),\n",
    ")\n",
    "\n",
    "output = model(input_tensor)\n",
    "print(output)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T08:50:28.517795Z",
     "start_time": "2024-03-05T08:50:28.499042Z"
    }
   },
   "id": "6ddec9fdb7246d4d",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1704, 0.2976, 0.1553, 0.3766]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input_tensor = torch.Tensor([[3, 4, 6, 7, 10, 12, 2, 3, 6, 8, 9]])\n",
    "\n",
    "# Update network below to perform a multi-class classification with four labels\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(11, 20),\n",
    "    nn.Linear(20, 12),\n",
    "    nn.Linear(12, 6),\n",
    "    nn.Linear(6, 4),\n",
    "    nn.Softmax()\n",
    ")\n",
    "\n",
    "output = model(input_tensor)\n",
    "print(output)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T08:51:27.262147Z",
     "start_time": "2024-03-05T08:51:27.252246Z"
    }
   },
   "id": "e14b9ec13a66bb49",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 3.,  4.,  6.,  7., 10., 12.,  2.,  3.,  6.,  8.,  9.]],\n       dtype=torch.float64)"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converts weights to float\n",
    "input_tensor.double()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T08:55:17.581671Z",
     "start_time": "2024-03-05T08:55:17.569261Z"
    }
   },
   "id": "e9f53b7bc1416bda",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0, 1, 0])"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "y = 1\n",
    "num_classes = 3\n",
    "\n",
    "# Create the one-hot encoded vector using NumPy\n",
    "one_hot_numpy = np.array([0, 1, 0])\n",
    "\n",
    "# Create the one-hot encoded vector using PyTorch\n",
    "one_hot_pytorch = F.one_hot(torch.tensor(1), num_classes=num_classes)\n",
    "one_hot_pytorch"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T08:57:56.423564Z",
     "start_time": "2024-03-05T08:57:56.419397Z"
    }
   },
   "id": "defbbb76a987cd44",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8.0619, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "scores = torch.tensor([[0.1, 6.0, -2.0, 3.2]])\n",
    "\n",
    "# Create a one-hot encoded vector of the label y\n",
    "one_hot_label = F.one_hot(torch.tensor([2]), num_classes=4)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "loss = criterion(scores.double(), one_hot_label.double())\n",
    "print(loss)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T09:04:23.809258Z",
     "start_time": "2024-03-05T09:04:23.797304Z"
    }
   },
   "id": "dd6d990167fbad49",
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(14.7288, dtype=torch.float64)"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion(one_hot_label.double(), scores.double())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T09:04:24.206138Z",
     "start_time": "2024-03-05T09:04:24.196972Z"
    }
   },
   "id": "fddd3f2c95cfaf60",
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "preds = torch.tensor([[-1.7153, 0.3799]], requires_grad=True)\n",
    "target = torch.tensor([[1., 0.]])\n",
    "\n",
    "weight = torch.tensor([[-1.8072, -2.9975, -1.2635, 1.2220, 1.3340, -0.4344, 1.2662, -0.7905,\n",
    "                        1.2092],\n",
    "                       [-0.1426, 1.0565, 1.1914, 0.4710, -0.8984, 0.0105, -1.1036, 1.6828,\n",
    "                        -0.4550]], requires_grad=True)\n",
    "bias = torch.tensor([-1.0820, -0.1427], requires_grad=True)\n",
    "\n",
    "# Calculate the loss\n",
    "loss = criterion(preds, target)\n",
    "\n",
    "# Compute the gradients of the loss\n",
    "loss.backward()\n",
    "\n",
    "# Display gradients of the weight and bias tensors in order\n",
    "print(weight.grad)\n",
    "print(bias.grad)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T09:16:22.493008Z",
     "start_time": "2024-03-05T09:16:22.482468Z"
    }
   },
   "id": "b8e837c27c7c8c82",
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.1104, -0.2084,  0.2161, -0.0777, -0.1249, -0.1602,  0.1975,  0.0779,\n",
      "          0.1963,  0.0383,  0.1426, -0.2423, -0.1312, -0.2143, -0.2388, -0.1544],\n",
      "        [ 0.1174,  0.0970, -0.0619, -0.2032, -0.0854,  0.1508, -0.1726, -0.1940,\n",
      "          0.1344, -0.0907, -0.0795,  0.0772,  0.1341, -0.0548, -0.0347,  0.0466],\n",
      "        [-0.0164, -0.0295, -0.1931, -0.0184,  0.0613,  0.1675, -0.0347,  0.1912,\n",
      "         -0.0741,  0.1185, -0.0195,  0.1501,  0.2221, -0.0139,  0.0750, -0.0704],\n",
      "        [ 0.2296,  0.0916, -0.0630, -0.1872, -0.1400,  0.2172, -0.2253,  0.0272,\n",
      "          0.0386,  0.0384,  0.1800, -0.0736,  0.2057, -0.1808, -0.2305, -0.2063],\n",
      "        [ 0.0166,  0.1517,  0.0709, -0.1940,  0.0069,  0.0053,  0.0383, -0.1530,\n",
      "          0.0742,  0.1176,  0.1786,  0.0956, -0.0290,  0.0522,  0.1287,  0.0394],\n",
      "        [-0.0481,  0.1816,  0.1736,  0.0006, -0.0176, -0.1875, -0.1685, -0.2057,\n",
      "          0.0290,  0.0378, -0.2135,  0.1526, -0.1997,  0.1362, -0.2145,  0.1709],\n",
      "        [-0.1266,  0.0191,  0.2013, -0.0628, -0.0928, -0.1112, -0.0548,  0.0221,\n",
      "          0.0202,  0.2288,  0.0138,  0.1663, -0.0896, -0.0560, -0.1863,  0.2263],\n",
      "        [-0.1457, -0.1938,  0.1206,  0.1237, -0.2000, -0.1439, -0.1102,  0.1786,\n",
      "         -0.0234,  0.1101, -0.0180, -0.0017,  0.1080, -0.1807, -0.1614, -0.0870]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0237, -0.2127], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(nn.Linear(16, 8),\n",
    "                      nn.Sigmoid(),\n",
    "                      nn.Linear(8, 2))\n",
    "\n",
    "# Access the weight of the first linear layer\n",
    "weight_0 = model[0].weight\n",
    "print(weight_0)\n",
    "# Access the bias of the second linear layer\n",
    "bias_1 = model[2].bias\n",
    "print(bias_1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T09:19:30.822013Z",
     "start_time": "2024-03-05T09:19:30.787417Z"
    }
   },
   "id": "1ff9a033ae24bd2d",
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "SGD (\nParameter Group 0\n    dampening: 0\n    differentiable: False\n    foreach: None\n    lr: 0.001\n    maximize: False\n    momentum: 0\n    nesterov: False\n    weight_decay: 0\n)"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Create the optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "optimizer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T09:23:52.070Z",
     "start_time": "2024-03-05T09:23:44.694283Z"
    }
   },
   "id": "30e5010d3e49c5ac",
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "loss = criterion(preds, target)\n",
    "loss.backward()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T09:24:04.510836Z",
     "start_time": "2024-03-05T09:24:04.483905Z"
    }
   },
   "id": "aed20385efe0d81a",
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "optimizer.step()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T09:25:10.969117Z",
     "start_time": "2024-03-05T09:25:10.956343Z"
    }
   },
   "id": "28c5878c5333d4c3",
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "SGD (\nParameter Group 0\n    dampening: 0\n    differentiable: False\n    foreach: None\n    lr: 0.001\n    maximize: False\n    momentum: 0\n    nesterov: False\n    weight_decay: 0\n)"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T09:25:16.605050Z",
     "start_time": "2024-03-05T09:25:16.591533Z"
    }
   },
   "id": "73759377e4f42a6e",
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81.0\n",
      "tensor(81., dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "y_hat = np.array(10)\n",
    "y = np.array(1)\n",
    "\n",
    "# Calculate the MSELoss using NumPy\n",
    "mse_numpy = np.mean((y - y_hat) ** 2)\n",
    "print(mse_numpy)\n",
    "# Create the MSELoss function\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Calculate the MSELoss using the created loss function\n",
    "mse_pytorch = criterion(torch.tensor(y_hat).double(), torch.tensor(y).double())\n",
    "print(mse_pytorch)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T09:33:58.814361Z",
     "start_time": "2024-03-05T09:33:58.780055Z"
    }
   },
   "id": "e6dd9b1eb8abe7aa",
   "execution_count": 51
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "# Create a ReLU function with PyTorch\n",
    "relu_pytorch = nn.ReLU()\n",
    "\n",
    "# Apply your ReLU function on x, and calculate gradients\n",
    "x = torch.tensor(-1.0, requires_grad=True)\n",
    "y = relu_pytorch(x)\n",
    "y.backward()\n",
    "\n",
    "# Print the gradient of the ReLU function for x\n",
    "gradient = x.grad\n",
    "print(gradient)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T09:48:54.188848Z",
     "start_time": "2024-03-05T09:48:54.161739Z"
    }
   },
   "id": "6dcc235d47bc075e",
   "execution_count": 52
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.1000)\n"
     ]
    }
   ],
   "source": [
    "# Create a leaky relu function in PyTorch\n",
    "leaky_relu_pytorch = nn.LeakyReLU(negative_slope=0.05)\n",
    "\n",
    "x = torch.tensor(-2.0)\n",
    "# Call the above function on the tensor x\n",
    "output = leaky_relu_pytorch(x)\n",
    "print(output)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T09:49:47.389400Z",
     "start_time": "2024-03-05T09:49:47.370529Z"
    }
   },
   "id": "540967faf8a9fbdc",
   "execution_count": 53
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "81"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = nn.Sequential(nn.Linear(16, 4),\n",
    "                      nn.Linear(4, 2),\n",
    "                      nn.Linear(2, 1))\n",
    "total = 0\n",
    "for param in model.parameters():\n",
    "    total += param.numel()\n",
    "total"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T10:05:27.140555Z",
     "start_time": "2024-03-05T10:05:27.107808Z"
    }
   },
   "id": "8055251171b4a467",
   "execution_count": 59
  },
  {
   "cell_type": "markdown",
   "source": [
    "![Learning Rate and Momentum](lr_vs_momentum.png \"Learning Rate and Momentum\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c6d3117f11a5f585"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.weight\n",
      "0.bias\n",
      "1.weight\n",
      "1.bias\n",
      "2.weight\n",
      "2.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(name)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T10:19:24.435744Z",
     "start_time": "2024-03-05T10:19:24.423867Z"
    }
   },
   "id": "88f2af709f761c7c",
   "execution_count": 61
  },
  {
   "cell_type": "markdown",
   "source": [
    "Choosing which layer to freeze is an empirical process but a good rule of thumb is to start with the first layers and go deeper."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7e338e8196b1d6df"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "\n",
    "    # Check if the parameters belong to the first layer\n",
    "    if name == '0.weight' or name == '0.bias':\n",
    "        # Freeze the parameters\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # Check if the parameters belong to the second layer\n",
    "    if name == '1.weight' or name == '1.bias':\n",
    "        # Freeze the parameters\n",
    "        param.requires_grad = False"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T10:20:40.047712Z",
     "start_time": "2024-03-05T10:20:40.025464Z"
    }
   },
   "id": "c8c2d957a9d8b5b5",
   "execution_count": 62
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0021, grad_fn=<MinBackward1>) tensor(0.9979, grad_fn=<MaxBackward1>)\n",
      "tensor(0.0002, grad_fn=<MinBackward1>) tensor(0.9999, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "layer0 = nn.Linear(16, 32)\n",
    "layer1 = nn.Linear(32, 64)\n",
    "\n",
    "# Use uniform initialization for layer0 and layer1 weights\n",
    "nn.init.uniform_(layer0.weight)\n",
    "nn.init.uniform_(layer1.weight)\n",
    "\n",
    "model = nn.Sequential(layer0, layer1)\n",
    "print(layer0.weight.min(), layer0.weight.max())\n",
    "print(layer1.weight.min(), layer1.weight.max())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T10:24:17.388956Z",
     "start_time": "2024-03-05T10:24:17.369654Z"
    }
   },
   "id": "45c7c0091ae135f1",
   "execution_count": 69
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([0.2368, 0.2278, 0.4657, 0.4628, 0.2790, 0.1873, 0.8502, 0.4834],\n",
      "       dtype=torch.float64), tensor([0.2075], dtype=torch.float64))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "np_features = np.array(np.random.rand(12, 8))\n",
    "np_target = np.array(np.random.rand(12, 1))\n",
    "\n",
    "# Convert arrays to PyTorch tensors\n",
    "torch_features = torch.tensor(np_features)\n",
    "torch_target = torch.tensor(np_target)\n",
    "\n",
    "# Create a TensorDataset from two tensors\n",
    "dataset = TensorDataset(torch_features, torch_target)\n",
    "\n",
    "# Return the last element of this dataset\n",
    "print(dataset[-1])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T10:31:13.759376Z",
     "start_time": "2024-03-05T10:31:13.731095Z"
    }
   },
   "id": "4833471f33f570e9",
   "execution_count": 71
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "            ph  Hardness    Solids  Chloramines   Sulfate  Conductivity  \\\n0     0.587349  0.577747  0.386298     0.568199  0.647347      0.292985   \n1     0.643654  0.441300  0.314381     0.439304  0.514545      0.356685   \n2     0.388934  0.470876  0.506122     0.524364  0.561537      0.142913   \n3     0.725820  0.715942  0.506141     0.521683  0.751819      0.148683   \n4     0.610517  0.532588  0.237701     0.270288  0.495155      0.494792   \n...        ...       ...       ...          ...       ...           ...   \n2006  0.636224  0.580511  0.277748     0.418063  0.522486      0.342184   \n2007  0.470143  0.548826  0.301347     0.538273  0.498565      0.231359   \n2008  0.817826  0.087434  0.656389     0.670774  0.369089      0.431872   \n2009  0.424187  0.464092  0.459656     0.541633  0.615572      0.388360   \n2010  0.322425  0.492891  0.841409     0.492136  0.656047      0.588709   \n\n      Organic_carbon  Trihalomethanes  Turbidity  Potability  \n0           0.654522         0.795029   0.630115           0  \n1           0.377248         0.202914   0.520358           0  \n2           0.249922         0.401487   0.219973           0  \n3           0.467200         0.658678   0.242428           0  \n4           0.409721         0.469762   0.585049           0  \n...              ...              ...        ...         ...  \n2006        0.310364         0.402799   0.627156           1  \n2007        0.565061         0.175889   0.395061           1  \n2008        0.563265         0.285745   0.578674           1  \n2009        0.397780         0.449156   0.440004           1  \n2010        0.471422         0.503458   0.591867           1  \n\n[2011 rows x 10 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ph</th>\n      <th>Hardness</th>\n      <th>Solids</th>\n      <th>Chloramines</th>\n      <th>Sulfate</th>\n      <th>Conductivity</th>\n      <th>Organic_carbon</th>\n      <th>Trihalomethanes</th>\n      <th>Turbidity</th>\n      <th>Potability</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.587349</td>\n      <td>0.577747</td>\n      <td>0.386298</td>\n      <td>0.568199</td>\n      <td>0.647347</td>\n      <td>0.292985</td>\n      <td>0.654522</td>\n      <td>0.795029</td>\n      <td>0.630115</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.643654</td>\n      <td>0.441300</td>\n      <td>0.314381</td>\n      <td>0.439304</td>\n      <td>0.514545</td>\n      <td>0.356685</td>\n      <td>0.377248</td>\n      <td>0.202914</td>\n      <td>0.520358</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.388934</td>\n      <td>0.470876</td>\n      <td>0.506122</td>\n      <td>0.524364</td>\n      <td>0.561537</td>\n      <td>0.142913</td>\n      <td>0.249922</td>\n      <td>0.401487</td>\n      <td>0.219973</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.725820</td>\n      <td>0.715942</td>\n      <td>0.506141</td>\n      <td>0.521683</td>\n      <td>0.751819</td>\n      <td>0.148683</td>\n      <td>0.467200</td>\n      <td>0.658678</td>\n      <td>0.242428</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.610517</td>\n      <td>0.532588</td>\n      <td>0.237701</td>\n      <td>0.270288</td>\n      <td>0.495155</td>\n      <td>0.494792</td>\n      <td>0.409721</td>\n      <td>0.469762</td>\n      <td>0.585049</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2006</th>\n      <td>0.636224</td>\n      <td>0.580511</td>\n      <td>0.277748</td>\n      <td>0.418063</td>\n      <td>0.522486</td>\n      <td>0.342184</td>\n      <td>0.310364</td>\n      <td>0.402799</td>\n      <td>0.627156</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2007</th>\n      <td>0.470143</td>\n      <td>0.548826</td>\n      <td>0.301347</td>\n      <td>0.538273</td>\n      <td>0.498565</td>\n      <td>0.231359</td>\n      <td>0.565061</td>\n      <td>0.175889</td>\n      <td>0.395061</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2008</th>\n      <td>0.817826</td>\n      <td>0.087434</td>\n      <td>0.656389</td>\n      <td>0.670774</td>\n      <td>0.369089</td>\n      <td>0.431872</td>\n      <td>0.563265</td>\n      <td>0.285745</td>\n      <td>0.578674</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2009</th>\n      <td>0.424187</td>\n      <td>0.464092</td>\n      <td>0.459656</td>\n      <td>0.541633</td>\n      <td>0.615572</td>\n      <td>0.388360</td>\n      <td>0.397780</td>\n      <td>0.449156</td>\n      <td>0.440004</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2010</th>\n      <td>0.322425</td>\n      <td>0.492891</td>\n      <td>0.841409</td>\n      <td>0.492136</td>\n      <td>0.656047</td>\n      <td>0.588709</td>\n      <td>0.471422</td>\n      <td>0.503458</td>\n      <td>0.591867</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>2011 rows × 10 columns</p>\n</div>"
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataframe = pd.read_csv('water_potability.csv')\n",
    "dataframe"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T10:32:44.117984Z",
     "start_time": "2024-03-05T10:32:40.162811Z"
    }
   },
   "id": "4568fa1ae2b99b1c",
   "execution_count": 72
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load the different columns into two PyTorch tensors\n",
    "features = torch.tensor(dataframe[['ph', 'Sulfate', 'Conductivity', 'Organic_carbon']].to_numpy()).float()\n",
    "target = torch.tensor(dataframe['Potability'].to_numpy()).float()\n",
    "\n",
    "# Create a dataset from the two generated tensors\n",
    "dataset = TensorDataset(features, target)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T10:33:52.139957Z",
     "start_time": "2024-03-05T10:33:52.125268Z"
    }
   },
   "id": "4e81960cae5c7b97",
   "execution_count": 74
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Create a dataloader using the above dataset\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "x, y = next(iter(dataloader))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T10:34:46.205954Z",
     "start_time": "2024-03-05T10:34:46.168450Z"
    }
   },
   "id": "55316df6871557b6",
   "execution_count": 75
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3716],\n",
      "        [0.4196],\n",
      "        [0.4039],\n",
      "        ...,\n",
      "        [0.3880],\n",
      "        [0.3829],\n",
      "        [0.3454]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Create a model using the nn.Sequential API\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(4, 10),\n",
    "    nn.Linear(10, 1)\n",
    ")\n",
    "output = model(features)\n",
    "print(output)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T10:35:39.155015Z",
     "start_time": "2024-03-05T10:35:39.111932Z"
    }
   },
   "id": "e89ae8190fffe410",
   "execution_count": 76
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(array([[[[0.38053016, 0.35004572, 0.38045538],\n          [0.49561382, 0.45045635, 0.47310239],\n          [0.5744727 , 0.51869527, 0.53720113],\n          ...,\n          [0.34580102, 0.29482917, 0.30817478],\n          [0.28303221, 0.24503852, 0.26706514],\n          [0.15621841, 0.14549615, 0.18887831]],\n \n         [[0.44942444, 0.40002741, 0.41653014],\n          [0.56823385, 0.50350932, 0.51621795],\n          [0.61456819, 0.54212599, 0.55860702],\n          ...,\n          [0.40559703, 0.35699659, 0.36157709],\n          [0.39955874, 0.35576992, 0.36392419],\n          [0.22050038, 0.19371628, 0.2253609 ]],\n \n         [[0.59694617, 0.52626227, 0.53245013],\n          [0.62542287, 0.5513043 , 0.5661661 ],\n          [0.62773799, 0.55528255, 0.57796426],\n          ...,\n          [0.43312883, 0.38273693, 0.38574492],\n          [0.44604589, 0.40381404, 0.40859798],\n          [0.32149855, 0.28387212, 0.29545527]],\n \n         ...,\n \n         [[0.51461386, 0.46347499, 0.45039961],\n          [0.49280163, 0.44433538, 0.42488051],\n          [0.33246312, 0.29534419, 0.29490718],\n          ...,\n          [0.09499688, 0.10771229, 0.17235971],\n          [0.17196673, 0.17564455, 0.23054096],\n          [0.4063567 , 0.36350965, 0.35570631]],\n \n         [[0.55496161, 0.49469325, 0.48359171],\n          [0.54389378, 0.4842707 , 0.4639853 ],\n          [0.46868891, 0.40938   , 0.39281277],\n          ...,\n          [0.04487414, 0.06040202, 0.12488677],\n          [0.06820151, 0.08171619, 0.1466867 ],\n          [0.10242083, 0.11323387, 0.17786427]],\n \n         [[0.52917802, 0.46531469, 0.46048517],\n          [0.51579902, 0.45446749, 0.43881026],\n          [0.46593831, 0.40541798, 0.38983242],\n          ...,\n          [0.03475207, 0.05034619, 0.11151596],\n          [0.04142761, 0.05735427, 0.11892009],\n          [0.05416931, 0.06922745, 0.13317869]]],\n \n \n        [[[0.02961101, 0.03669857, 0.03601812],\n          [0.03738837, 0.03973504, 0.03439426],\n          [0.05302555, 0.04874867, 0.04643046],\n          ...,\n          [0.39129168, 0.3488658 , 0.29704544],\n          [0.39476423, 0.35174968, 0.29771708],\n          [0.39278588, 0.35357557, 0.30594901]],\n \n         [[0.03463653, 0.04041096, 0.04037499],\n          [0.03454232, 0.039954  , 0.03845631],\n          [0.04252591, 0.04267892, 0.03847355],\n          ...,\n          [0.38482365, 0.34185549, 0.28746543],\n          [0.38436398, 0.34319024, 0.29405173],\n          [0.37715893, 0.34216769, 0.29717416]],\n \n         [[0.03172345, 0.03937263, 0.03938058],\n          [0.02925047, 0.03554628, 0.03697507],\n          [0.03372705, 0.03814145, 0.03721272],\n          ...,\n          [0.37047827, 0.33130611, 0.27950048],\n          [0.37082623, 0.33229502, 0.28656472],\n          [0.36329531, 0.33008992, 0.29204261]],\n \n         ...,\n \n         [[0.86189571, 0.90846603, 0.93238644],\n          [0.85745273, 0.90240757, 0.92703298],\n          [0.85282938, 0.8972492 , 0.92408522],\n          ...,\n          [0.61537365, 0.63154388, 0.65973912],\n          [0.61653847, 0.62449789, 0.65284   ],\n          [0.50606191, 0.51639512, 0.54395853]],\n \n         [[0.79411012, 0.84837345, 0.87809972],\n          [0.77291017, 0.83253576, 0.86051095],\n          [0.76397485, 0.8276025 , 0.8539051 ],\n          ...,\n          [0.65769912, 0.67481733, 0.70424736],\n          [0.67000832, 0.68389254, 0.71361497],\n          [0.58687257, 0.60599313, 0.63915132]],\n \n         [[0.80734131, 0.86803077, 0.89397692],\n          [0.79233044, 0.85755448, 0.88663423],\n          [0.79625986, 0.86180063, 0.89130733],\n          ...,\n          [0.72733366, 0.73905715, 0.76470859],\n          [0.73948615, 0.7475787 , 0.77307222],\n          [0.65181565, 0.66610702, 0.69550301]]],\n \n \n        [[[0.19903756, 0.15050398, 0.08101131],\n          [0.3720293 , 0.28470186, 0.19280789],\n          [0.5478849 , 0.43282308, 0.31941652],\n          ...,\n          [0.61490403, 0.50178604, 0.3611179 ],\n          [0.32947019, 0.26353947, 0.16200371],\n          [0.26366125, 0.21747648, 0.1336921 ]],\n \n         [[0.21701779, 0.16432867, 0.09262666],\n          [0.39822073, 0.30787435, 0.21286155],\n          [0.59445617, 0.46860984, 0.35872262],\n          ...,\n          [0.83977121, 0.706385  , 0.5412121 ],\n          [0.56284581, 0.45983592, 0.32729056],\n          [0.23718454, 0.1846413 , 0.09878849]],\n \n         [[0.22684653, 0.17117372, 0.09525009],\n          [0.41281134, 0.32278666, 0.22036732],\n          [0.5793281 , 0.4553544 , 0.34977506],\n          ...,\n          [0.84883105, 0.71830474, 0.55559436],\n          [0.76926556, 0.64580085, 0.49390595],\n          [0.29624773, 0.23136157, 0.1341953 ]],\n \n         ...,\n \n         [[0.33809533, 0.3390254 , 0.41843424],\n          [0.33417162, 0.34030252, 0.45561168],\n          [0.28329637, 0.29772994, 0.44444456],\n          ...,\n          [0.56374811, 0.44154563, 0.32799325],\n          [0.37703193, 0.30000488, 0.21981335],\n          [0.2310167 , 0.21802335, 0.25983299]],\n \n         [[0.3439559 , 0.35176625, 0.47018298],\n          [0.38368257, 0.39456731, 0.52578085],\n          [0.30799688, 0.32171997, 0.47564753],\n          ...,\n          [0.55063726, 0.43227678, 0.32047779],\n          [0.28587398, 0.22663087, 0.1644927 ],\n          [0.25275389, 0.24471804, 0.31613437]],\n \n         [[0.35899856, 0.37270243, 0.51942085],\n          [0.37159654, 0.38564336, 0.5467618 ],\n          [0.35162036, 0.36796731, 0.53363866],\n          ...,\n          [0.52377758, 0.41852155, 0.31322119],\n          [0.24479471, 0.20526291, 0.17256758],\n          [0.30304076, 0.30945174, 0.44053475]]],\n \n \n        ...,\n \n \n        [[[0.44143836, 0.34030383, 0.28550467],\n          [0.4361966 , 0.34776711, 0.29513275],\n          [0.11000363, 0.10378341, 0.09558224],\n          ...,\n          [0.11148522, 0.1217358 , 0.12852016],\n          [0.11368423, 0.12558332, 0.13049608],\n          [0.13282062, 0.14410546, 0.15194401]],\n \n         [[0.39705326, 0.31693192, 0.27060819],\n          [0.17569336, 0.15350903, 0.14418743],\n          [0.06581831, 0.07209755, 0.07211414],\n          ...,\n          [0.10926541, 0.12243188, 0.12710585],\n          [0.12787764, 0.14192806, 0.14585261],\n          [0.11513676, 0.12877012, 0.13634974]],\n \n         [[0.30901406, 0.26461709, 0.23319395],\n          [0.06785007, 0.08009209, 0.08203196],\n          [0.08866489, 0.08074652, 0.07869462],\n          ...,\n          [0.10279623, 0.1154815 , 0.11973727],\n          [0.12975895, 0.1427306 , 0.14611924],\n          [0.12143342, 0.1332312 , 0.13786404]],\n \n         ...,\n \n         [[0.66458506, 0.50830652, 0.45536348],\n          [0.68276266, 0.5396744 , 0.48453285],\n          [0.65554422, 0.5374521 , 0.48785885],\n          ...,\n          [0.12423009, 0.1320057 , 0.1365505 ],\n          [0.41079372, 0.41937299, 0.41663222],\n          [0.42457562, 0.43279491, 0.43145379]],\n \n         [[0.62373675, 0.45384626, 0.40314621],\n          [0.60669572, 0.44442188, 0.39006576],\n          [0.62393415, 0.48506716, 0.43092034],\n          ...,\n          [0.03777999, 0.04715961, 0.05414489],\n          [0.26990383, 0.28283331, 0.28526253],\n          [0.4190779 , 0.43126417, 0.42785989]],\n \n         [[0.59535126, 0.4227506 , 0.37318041],\n          [0.55781265, 0.39583737, 0.34200618],\n          [0.58896412, 0.45338915, 0.41368445],\n          ...,\n          [0.03076868, 0.03667097, 0.04648436],\n          [0.10579465, 0.11581047, 0.12547869],\n          [0.42542734, 0.43831169, 0.43038192]]],\n \n \n        [[[0.13834625, 0.12952721, 0.14359074],\n          [0.09454771, 0.07372329, 0.0955367 ],\n          [0.16518132, 0.1106205 , 0.11727736],\n          ...,\n          [0.44632305, 0.34458886, 0.30818505],\n          [0.27550504, 0.21504959, 0.21844193],\n          [0.12815288, 0.09740557, 0.12070954]],\n \n         [[0.09445868, 0.07312175, 0.1043937 ],\n          [0.15002729, 0.1107459 , 0.12416763],\n          [0.35355979, 0.27256407, 0.26048598],\n          ...,\n          [0.42612511, 0.31713109, 0.27584976],\n          [0.22804424, 0.1559801 , 0.14783738],\n          [0.09878516, 0.06811116, 0.08108881]],\n \n         [[0.13876698, 0.1022346 , 0.13604951],\n          [0.2586817 , 0.19838745, 0.2120625 ],\n          [0.50330632, 0.40499362, 0.38055171],\n          ...,\n          [0.4737505 , 0.36275788, 0.31366613],\n          [0.25847795, 0.17978934, 0.16379029],\n          [0.09657376, 0.06418239, 0.07124552]],\n \n         ...,\n \n         [[0.61346693, 0.60795488, 0.60323952],\n          [0.57897118, 0.59243804, 0.61347265],\n          [0.28226111, 0.26250248, 0.27886805],\n          ...,\n          [0.37115985, 0.36742031, 0.39295246],\n          [0.35551112, 0.31824866, 0.34307867],\n          [0.37533048, 0.32690591, 0.344104  ]],\n \n         [[0.57723919, 0.57172547, 0.5652064 ],\n          [0.57793633, 0.59203279, 0.6110431 ],\n          [0.4155574 , 0.41000238, 0.42281669],\n          ...,\n          [0.41988722, 0.41966153, 0.45252164],\n          [0.43816137, 0.39710471, 0.43075976],\n          [0.59531226, 0.54903191, 0.58664396]],\n \n         [[0.57638739, 0.553787  , 0.55877902],\n          [0.56474226, 0.55585542, 0.56639099],\n          [0.4708975 , 0.46642084, 0.46805382],\n          ...,\n          [0.5200705 , 0.52445947, 0.5294219 ],\n          [0.39310581, 0.38072379, 0.38521764],\n          [0.47951718, 0.4386599 , 0.43313132]]],\n \n \n        [[[0.10219077, 0.07436781, 0.05040369],\n          [0.10659198, 0.07820702, 0.0590368 ],\n          [0.09282353, 0.06326935, 0.04528085],\n          ...,\n          [0.54793227, 0.44005005, 0.36313747],\n          [0.54426201, 0.45688539, 0.36368868],\n          [0.61297566, 0.52689097, 0.42989441]],\n \n         [[0.09292399, 0.06635117, 0.03334834],\n          [0.09912972, 0.07171542, 0.04138654],\n          [0.10201933, 0.07494051, 0.04472105],\n          ...,\n          [0.53314525, 0.41689497, 0.31419167],\n          [0.61377661, 0.53569698, 0.44072578],\n          [0.80383127, 0.7672455 , 0.69480861]],\n \n         [[0.10449474, 0.07579738, 0.04293087],\n          [0.10709222, 0.08083203, 0.04618284],\n          [0.11794002, 0.09112999, 0.0576936 ],\n          ...,\n          [0.67840504, 0.60518285, 0.5381673 ],\n          [0.86465079, 0.82458755, 0.77469873],\n          [0.93080938, 0.91255307, 0.87025154]],\n \n         ...,\n \n         [[0.89553684, 0.81879566, 0.80345449],\n          [0.89400669, 0.81823011, 0.80145745],\n          [0.88054993, 0.8043122 , 0.78698076],\n          ...,\n          [0.7688179 , 0.79539567, 0.7141015 ],\n          [0.77385818, 0.79515084, 0.7172328 ],\n          [0.77846709, 0.79816546, 0.72088873]],\n \n         [[0.87999019, 0.79849198, 0.77022437],\n          [0.87164106, 0.78583375, 0.75728285],\n          [0.86904986, 0.77533334, 0.75047445],\n          ...,\n          [0.77647537, 0.81549799, 0.73400809],\n          [0.78353586, 0.82182886, 0.73797273],\n          [0.79631353, 0.82671324, 0.7363838 ]],\n \n         [[0.84959287, 0.75282162, 0.71558299],\n          [0.8466399 , 0.74077823, 0.70353097],\n          [0.84008855, 0.7249987 , 0.69109652],\n          ...,\n          [0.76427852, 0.81889335, 0.75715831],\n          [0.77502332, 0.8228931 , 0.75887504],\n          [0.78799407, 0.82799105, 0.75730586]]]]),\n array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2,\n        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n        2, 2, 2]))"
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_dataset = pd.read_pickle('masks_dataset.pickle')\n",
    "mask_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T10:58:04.704941Z",
     "start_time": "2024-03-05T10:58:04.664932Z"
    }
   },
   "id": "c8905d6b93feed9e",
   "execution_count": 83
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(array([[[[0.38053016, 0.35004572, 0.38045538],\n          [0.49561382, 0.45045635, 0.47310239],\n          [0.5744727 , 0.51869527, 0.53720113],\n          ...,\n          [0.34580102, 0.29482917, 0.30817478],\n          [0.28303221, 0.24503852, 0.26706514],\n          [0.15621841, 0.14549615, 0.18887831]],\n \n         [[0.44942444, 0.40002741, 0.41653014],\n          [0.56823385, 0.50350932, 0.51621795],\n          [0.61456819, 0.54212599, 0.55860702],\n          ...,\n          [0.40559703, 0.35699659, 0.36157709],\n          [0.39955874, 0.35576992, 0.36392419],\n          [0.22050038, 0.19371628, 0.2253609 ]],\n \n         [[0.59694617, 0.52626227, 0.53245013],\n          [0.62542287, 0.5513043 , 0.5661661 ],\n          [0.62773799, 0.55528255, 0.57796426],\n          ...,\n          [0.43312883, 0.38273693, 0.38574492],\n          [0.44604589, 0.40381404, 0.40859798],\n          [0.32149855, 0.28387212, 0.29545527]],\n \n         ...,\n \n         [[0.51461386, 0.46347499, 0.45039961],\n          [0.49280163, 0.44433538, 0.42488051],\n          [0.33246312, 0.29534419, 0.29490718],\n          ...,\n          [0.09499688, 0.10771229, 0.17235971],\n          [0.17196673, 0.17564455, 0.23054096],\n          [0.4063567 , 0.36350965, 0.35570631]],\n \n         [[0.55496161, 0.49469325, 0.48359171],\n          [0.54389378, 0.4842707 , 0.4639853 ],\n          [0.46868891, 0.40938   , 0.39281277],\n          ...,\n          [0.04487414, 0.06040202, 0.12488677],\n          [0.06820151, 0.08171619, 0.1466867 ],\n          [0.10242083, 0.11323387, 0.17786427]],\n \n         [[0.52917802, 0.46531469, 0.46048517],\n          [0.51579902, 0.45446749, 0.43881026],\n          [0.46593831, 0.40541798, 0.38983242],\n          ...,\n          [0.03475207, 0.05034619, 0.11151596],\n          [0.04142761, 0.05735427, 0.11892009],\n          [0.05416931, 0.06922745, 0.13317869]]],\n \n \n        [[[0.02961101, 0.03669857, 0.03601812],\n          [0.03738837, 0.03973504, 0.03439426],\n          [0.05302555, 0.04874867, 0.04643046],\n          ...,\n          [0.39129168, 0.3488658 , 0.29704544],\n          [0.39476423, 0.35174968, 0.29771708],\n          [0.39278588, 0.35357557, 0.30594901]],\n \n         [[0.03463653, 0.04041096, 0.04037499],\n          [0.03454232, 0.039954  , 0.03845631],\n          [0.04252591, 0.04267892, 0.03847355],\n          ...,\n          [0.38482365, 0.34185549, 0.28746543],\n          [0.38436398, 0.34319024, 0.29405173],\n          [0.37715893, 0.34216769, 0.29717416]],\n \n         [[0.03172345, 0.03937263, 0.03938058],\n          [0.02925047, 0.03554628, 0.03697507],\n          [0.03372705, 0.03814145, 0.03721272],\n          ...,\n          [0.37047827, 0.33130611, 0.27950048],\n          [0.37082623, 0.33229502, 0.28656472],\n          [0.36329531, 0.33008992, 0.29204261]],\n \n         ...,\n \n         [[0.86189571, 0.90846603, 0.93238644],\n          [0.85745273, 0.90240757, 0.92703298],\n          [0.85282938, 0.8972492 , 0.92408522],\n          ...,\n          [0.61537365, 0.63154388, 0.65973912],\n          [0.61653847, 0.62449789, 0.65284   ],\n          [0.50606191, 0.51639512, 0.54395853]],\n \n         [[0.79411012, 0.84837345, 0.87809972],\n          [0.77291017, 0.83253576, 0.86051095],\n          [0.76397485, 0.8276025 , 0.8539051 ],\n          ...,\n          [0.65769912, 0.67481733, 0.70424736],\n          [0.67000832, 0.68389254, 0.71361497],\n          [0.58687257, 0.60599313, 0.63915132]],\n \n         [[0.80734131, 0.86803077, 0.89397692],\n          [0.79233044, 0.85755448, 0.88663423],\n          [0.79625986, 0.86180063, 0.89130733],\n          ...,\n          [0.72733366, 0.73905715, 0.76470859],\n          [0.73948615, 0.7475787 , 0.77307222],\n          [0.65181565, 0.66610702, 0.69550301]]],\n \n \n        [[[0.19903756, 0.15050398, 0.08101131],\n          [0.3720293 , 0.28470186, 0.19280789],\n          [0.5478849 , 0.43282308, 0.31941652],\n          ...,\n          [0.61490403, 0.50178604, 0.3611179 ],\n          [0.32947019, 0.26353947, 0.16200371],\n          [0.26366125, 0.21747648, 0.1336921 ]],\n \n         [[0.21701779, 0.16432867, 0.09262666],\n          [0.39822073, 0.30787435, 0.21286155],\n          [0.59445617, 0.46860984, 0.35872262],\n          ...,\n          [0.83977121, 0.706385  , 0.5412121 ],\n          [0.56284581, 0.45983592, 0.32729056],\n          [0.23718454, 0.1846413 , 0.09878849]],\n \n         [[0.22684653, 0.17117372, 0.09525009],\n          [0.41281134, 0.32278666, 0.22036732],\n          [0.5793281 , 0.4553544 , 0.34977506],\n          ...,\n          [0.84883105, 0.71830474, 0.55559436],\n          [0.76926556, 0.64580085, 0.49390595],\n          [0.29624773, 0.23136157, 0.1341953 ]],\n \n         ...,\n \n         [[0.33809533, 0.3390254 , 0.41843424],\n          [0.33417162, 0.34030252, 0.45561168],\n          [0.28329637, 0.29772994, 0.44444456],\n          ...,\n          [0.56374811, 0.44154563, 0.32799325],\n          [0.37703193, 0.30000488, 0.21981335],\n          [0.2310167 , 0.21802335, 0.25983299]],\n \n         [[0.3439559 , 0.35176625, 0.47018298],\n          [0.38368257, 0.39456731, 0.52578085],\n          [0.30799688, 0.32171997, 0.47564753],\n          ...,\n          [0.55063726, 0.43227678, 0.32047779],\n          [0.28587398, 0.22663087, 0.1644927 ],\n          [0.25275389, 0.24471804, 0.31613437]],\n \n         [[0.35899856, 0.37270243, 0.51942085],\n          [0.37159654, 0.38564336, 0.5467618 ],\n          [0.35162036, 0.36796731, 0.53363866],\n          ...,\n          [0.52377758, 0.41852155, 0.31322119],\n          [0.24479471, 0.20526291, 0.17256758],\n          [0.30304076, 0.30945174, 0.44053475]]],\n \n \n        ...,\n \n \n        [[[0.44143836, 0.34030383, 0.28550467],\n          [0.4361966 , 0.34776711, 0.29513275],\n          [0.11000363, 0.10378341, 0.09558224],\n          ...,\n          [0.11148522, 0.1217358 , 0.12852016],\n          [0.11368423, 0.12558332, 0.13049608],\n          [0.13282062, 0.14410546, 0.15194401]],\n \n         [[0.39705326, 0.31693192, 0.27060819],\n          [0.17569336, 0.15350903, 0.14418743],\n          [0.06581831, 0.07209755, 0.07211414],\n          ...,\n          [0.10926541, 0.12243188, 0.12710585],\n          [0.12787764, 0.14192806, 0.14585261],\n          [0.11513676, 0.12877012, 0.13634974]],\n \n         [[0.30901406, 0.26461709, 0.23319395],\n          [0.06785007, 0.08009209, 0.08203196],\n          [0.08866489, 0.08074652, 0.07869462],\n          ...,\n          [0.10279623, 0.1154815 , 0.11973727],\n          [0.12975895, 0.1427306 , 0.14611924],\n          [0.12143342, 0.1332312 , 0.13786404]],\n \n         ...,\n \n         [[0.66458506, 0.50830652, 0.45536348],\n          [0.68276266, 0.5396744 , 0.48453285],\n          [0.65554422, 0.5374521 , 0.48785885],\n          ...,\n          [0.12423009, 0.1320057 , 0.1365505 ],\n          [0.41079372, 0.41937299, 0.41663222],\n          [0.42457562, 0.43279491, 0.43145379]],\n \n         [[0.62373675, 0.45384626, 0.40314621],\n          [0.60669572, 0.44442188, 0.39006576],\n          [0.62393415, 0.48506716, 0.43092034],\n          ...,\n          [0.03777999, 0.04715961, 0.05414489],\n          [0.26990383, 0.28283331, 0.28526253],\n          [0.4190779 , 0.43126417, 0.42785989]],\n \n         [[0.59535126, 0.4227506 , 0.37318041],\n          [0.55781265, 0.39583737, 0.34200618],\n          [0.58896412, 0.45338915, 0.41368445],\n          ...,\n          [0.03076868, 0.03667097, 0.04648436],\n          [0.10579465, 0.11581047, 0.12547869],\n          [0.42542734, 0.43831169, 0.43038192]]],\n \n \n        [[[0.13834625, 0.12952721, 0.14359074],\n          [0.09454771, 0.07372329, 0.0955367 ],\n          [0.16518132, 0.1106205 , 0.11727736],\n          ...,\n          [0.44632305, 0.34458886, 0.30818505],\n          [0.27550504, 0.21504959, 0.21844193],\n          [0.12815288, 0.09740557, 0.12070954]],\n \n         [[0.09445868, 0.07312175, 0.1043937 ],\n          [0.15002729, 0.1107459 , 0.12416763],\n          [0.35355979, 0.27256407, 0.26048598],\n          ...,\n          [0.42612511, 0.31713109, 0.27584976],\n          [0.22804424, 0.1559801 , 0.14783738],\n          [0.09878516, 0.06811116, 0.08108881]],\n \n         [[0.13876698, 0.1022346 , 0.13604951],\n          [0.2586817 , 0.19838745, 0.2120625 ],\n          [0.50330632, 0.40499362, 0.38055171],\n          ...,\n          [0.4737505 , 0.36275788, 0.31366613],\n          [0.25847795, 0.17978934, 0.16379029],\n          [0.09657376, 0.06418239, 0.07124552]],\n \n         ...,\n \n         [[0.61346693, 0.60795488, 0.60323952],\n          [0.57897118, 0.59243804, 0.61347265],\n          [0.28226111, 0.26250248, 0.27886805],\n          ...,\n          [0.37115985, 0.36742031, 0.39295246],\n          [0.35551112, 0.31824866, 0.34307867],\n          [0.37533048, 0.32690591, 0.344104  ]],\n \n         [[0.57723919, 0.57172547, 0.5652064 ],\n          [0.57793633, 0.59203279, 0.6110431 ],\n          [0.4155574 , 0.41000238, 0.42281669],\n          ...,\n          [0.41988722, 0.41966153, 0.45252164],\n          [0.43816137, 0.39710471, 0.43075976],\n          [0.59531226, 0.54903191, 0.58664396]],\n \n         [[0.57638739, 0.553787  , 0.55877902],\n          [0.56474226, 0.55585542, 0.56639099],\n          [0.4708975 , 0.46642084, 0.46805382],\n          ...,\n          [0.5200705 , 0.52445947, 0.5294219 ],\n          [0.39310581, 0.38072379, 0.38521764],\n          [0.47951718, 0.4386599 , 0.43313132]]],\n \n \n        [[[0.10219077, 0.07436781, 0.05040369],\n          [0.10659198, 0.07820702, 0.0590368 ],\n          [0.09282353, 0.06326935, 0.04528085],\n          ...,\n          [0.54793227, 0.44005005, 0.36313747],\n          [0.54426201, 0.45688539, 0.36368868],\n          [0.61297566, 0.52689097, 0.42989441]],\n \n         [[0.09292399, 0.06635117, 0.03334834],\n          [0.09912972, 0.07171542, 0.04138654],\n          [0.10201933, 0.07494051, 0.04472105],\n          ...,\n          [0.53314525, 0.41689497, 0.31419167],\n          [0.61377661, 0.53569698, 0.44072578],\n          [0.80383127, 0.7672455 , 0.69480861]],\n \n         [[0.10449474, 0.07579738, 0.04293087],\n          [0.10709222, 0.08083203, 0.04618284],\n          [0.11794002, 0.09112999, 0.0576936 ],\n          ...,\n          [0.67840504, 0.60518285, 0.5381673 ],\n          [0.86465079, 0.82458755, 0.77469873],\n          [0.93080938, 0.91255307, 0.87025154]],\n \n         ...,\n \n         [[0.89553684, 0.81879566, 0.80345449],\n          [0.89400669, 0.81823011, 0.80145745],\n          [0.88054993, 0.8043122 , 0.78698076],\n          ...,\n          [0.7688179 , 0.79539567, 0.7141015 ],\n          [0.77385818, 0.79515084, 0.7172328 ],\n          [0.77846709, 0.79816546, 0.72088873]],\n \n         [[0.87999019, 0.79849198, 0.77022437],\n          [0.87164106, 0.78583375, 0.75728285],\n          [0.86904986, 0.77533334, 0.75047445],\n          ...,\n          [0.77647537, 0.81549799, 0.73400809],\n          [0.78353586, 0.82182886, 0.73797273],\n          [0.79631353, 0.82671324, 0.7363838 ]],\n \n         [[0.84959287, 0.75282162, 0.71558299],\n          [0.8466399 , 0.74077823, 0.70353097],\n          [0.84008855, 0.7249987 , 0.69109652],\n          ...,\n          [0.76427852, 0.81889335, 0.75715831],\n          [0.77502332, 0.8228931 , 0.75887504],\n          [0.78799407, 0.82799105, 0.75730586]]]]),\n array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2,\n        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n        2, 2, 2]))"
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_dataset[0], mask_dataset[1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T10:59:48.295525Z",
     "start_time": "2024-03-05T10:59:48.245724Z"
    }
   },
   "id": "2ea3aed56582f4b8",
   "execution_count": 90
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "((355, 32, 32, 3), (355,))"
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_dataset[0].shape, mask_dataset[1].shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T13:04:36.520681Z",
     "start_time": "2024-03-05T13:04:36.496290Z"
    }
   },
   "id": "1e9388ce543820dd",
   "execution_count": 140
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Flatten(start_dim=1, end_dim=-1)\n",
      "  (1): Linear(in_features=3072, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torchmetrics\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "features, target = mask_dataset\n",
    "# Create a dataset from the two generated tensors\n",
    "dataset = TensorDataset(torch.tensor(features).float(), torch.tensor(target).float())\n",
    "dataloader = DataLoader(dataset, batch_size=10, shuffle=True)\n",
    "\n",
    "mean = (features / 255).reshape(3,-1).mean(axis=1)\n",
    "std = (features / 255).reshape(3,-1).std(axis=1)\n",
    "\n",
    "model = nn.Sequential(\n",
    "    # transforms.Normalize(list(mean), list(std)),\n",
    "    nn.Flatten(start_dim=1, end_dim=-1),\n",
    "    nn.Linear(3072, 3)\n",
    ")\n",
    "print(model)\n",
    "\n",
    "metric = torchmetrics.Accuracy(task=\"multiclass\", num_classes=3)\n",
    "for data in dataloader:\n",
    "    features, labels = data\n",
    "    outputs = model(features)\n",
    "    # Calculate accuracy over the batch\n",
    "    acc = metric(outputs.argmax(dim=-1), labels)\n",
    "\n",
    "# Calculate accuracy over the whole epoch\n",
    "acc = metric.compute()\n",
    "\n",
    "# Reset the metric for the next epoch \n",
    "metric.reset()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T13:43:38.012020Z",
     "start_time": "2024-03-05T13:43:37.949044Z"
    }
   },
   "id": "16adc89cb1c2f87f",
   "execution_count": 214
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(0.4254)"
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T13:43:38.318596Z",
     "start_time": "2024-03-05T13:43:38.268397Z"
    }
   },
   "id": "550f908479352d31",
   "execution_count": 215
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000, 36.9740,  0.0000,  0.0000,\n          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n       grad_fn=<MulBackward0>)"
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(11,16),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=0.8)\n",
    ")\n",
    "model(input_tensor)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T13:50:11.280101Z",
     "start_time": "2024-03-05T13:50:11.238699Z"
    }
   },
   "id": "b6e3dca0e5b8562b",
   "execution_count": 218
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "11dc44ea5b4ef034"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
